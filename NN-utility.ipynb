{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN-utility.ipynb","provenance":[],"authorship_tag":"ABX9TyPLLmRjsIE0JLwiCW92Socj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ARmQeGe9Xd2F","colab_type":"code","colab":{}},"source":["# This is a memo of ANN, CNN-Con1D, CNN-Con2D and ENN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwA9WHuaXqL1","colab_type":"code","colab":{}},"source":["# Always do this step first. It authrize you the path below.\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fv3sZ4gWYDZt","colab_type":"code","colab":{}},"source":["#must have this part if using the local files and import local modules!!\n","\n","rpath='/content/drive/My Drive/ML-colab/' #the root path.\n","fpath= rpath + 'deep-learn/image-class-CNN/'  #the path for data file\n","\n","import sys  #utilized the auto-selection module that I developed\n","sys.path.append(rpath+'ML-tune/')  #append path for ML-tune. \n","import ml_tune as tune  #A module to select the best model & hyperparameter \n","import ml_utility as ut  #a module to plot, trasnform, select features... "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCRDQEwoYEc5","colab_type":"code","colab":{}},"source":["import keras\n","keras.__version__\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Dense \n","from keras.layers import Conv1D, BatchNormalization, MaxPooling2D,Flatten,LSTM\n","from keras.constraints import maxnorm\n","from keras.optimizers import SGD, RMSprop, Adam\n","from keras.utils import np_utils, to_categorical\n","from keras import backend as K\n","#K.set_image_dim_ordering('th')\n","from sklearn.model_selection import GridSearchCV\n","from keras.wrappers.scikit_learn import KerasClassifier\n","#from keras.datasets import cifar10  #load data\n","import numpy as np\n","np.random.seed(1337) # for reproducibility\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1Who6sqYEkV","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdGu4-3wYEoD","colab_type":"code","colab":{}},"source":["#----- ANN----Dense only.  (this can be compared with the traditional method)\n","\n","#standarize the training and testing data (Robust, MinMax, Standard)\n","#NN needs numpy data type. (it seems that 'MinMax' is better)\n","#X_train, X_test=ut.data_scalor(X_train0, X_test0, data_type='np',scale_type='MinMax')\n","\n","#--------------------------\n","\n","model=Sequential()\n","\n","#convolution layer\n","model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n","#model.add(Dropout(0.2)) \n","model.add(Dense(units=64, activation='relu'))\n","#model.add(Dropout(0.3)) \n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dense(units=1, activation='sigmoid'))\n","print(model.summary())\n","\n","\n","#model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00005), metrics=['accuracy'])\n","\n","#history=model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=1)\n","#or use validation_split , batch_size=10,\n","history=model.fit(X_train, y_train,  epochs=50, validation_split=0.25, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNz7jivrYaJ_","colab_type":"code","colab":{}},"source":["#----- CNN----Conv1D.  (this can be compared with the traditional method)\n","\n","#data must be reshaped:\n","x_train=np.array(x_train).reshape(x_train.shape[0],x_train.shape[1],1)\n","x_test=np.array(x_test).reshape(x_test.shape[0],x_test.shape[1],1)\n","\n","#build model !\n","from keras import regularizers\n","np.random.seed(1337)\n","print('Building model...')\n","\n","#creat the architecture\n","model=Sequential()\n","\n","#convolution layer\n","model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(x_train[0].shape)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))  #drop 20% neurons randomly\n","\n","#the second layer\n","model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))  #drop 50% neurons randomly\n","#the second layer\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))  #drop 50% neurons randomly\n","\n","#Flatten layer\n","model.add(Flatten())\n","model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.09)))\n","model.add(Dropout(0.3))  #drop 50% neurons randomly\n","#model.add(Dense(64, activation='relu'))\n","\n","#Note: here the activation makes a huge difference\n","#model.add(Dense(1, activation='softmax'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary()\n","\n","#-----------#compile the model\n","#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n","\n","#train the model. assign it to history so as to use it later!\n","#history=model.fit(x_train, y_train, batch_size=10, epochs=50, validation_split=0.3)\n","history=model.fit(x_train, y_train, epochs=35, validation_data=(x_test, y_test),\n","                  verbose=1, shuffle=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwJwmIL2YaNQ","colab_type":"code","colab":{}},"source":["#----- CNN----Conv2D.  (this is for image classificatin)\n","\n","\n","def swish_activation(x):\n","    return (K.sigmoid(x) * x)\n","\n","model = Sequential()\n","model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=X_train.shape[1:]))\n","model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=X_train.shape[1:]))\n","model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n","model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n","model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n","model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(64, activation=swish_activation, kernel_regularizer=regularizers.l2(0.01)))\n","model.add(Dropout(0.4))\n","model.add(Dense(2 , activation='sigmoid'))\n","\n","\n","print(model.summary())\n","\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00005), metrics=['accuracy'])\n","history1=model.fit(X_train, y_train, epochs=6, batch_size = 256, \n","                   validation_data=(X_test, y_test), verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWNilNiHYaQp","colab_type":"code","colab":{}},"source":["##One-Hot Encoding: convert labels (uint8) to categorical numbers.\n","#otherwise, the numbers will be considered as integers\n","#looks like 10 numbers ()\n","y_train_oh=to_categorical(y_train)\n","y_test_oh=to_categorical(y_test)\n","print ('y_train.dtype:',y_train.dtype, \" , \" , 'y_train_oh.dtype:',y_train_oh.dtype )\n","print(\"before encoding:\", y_train.shape, \", after Encoding:\",y_train_oh.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbsaZA8zYErs","colab_type":"code","colab":{}},"source":["#----RNN----\n","#RNN models (if return_sequences=True, the batch shape will be the same)\n","model=Sequential()\n","model.add(LSTM((1),batch_input_shape=(None, 5,1), return_sequences=True))\n","model.add(LSTM((1), return_sequences=False))\n","print(model.summary())\n","\n","model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhPjRMILYEvm","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}